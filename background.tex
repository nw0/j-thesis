\documentclass[thesis.tex]{subfile}

% Purpose of background chapter
% 1. Background to understand thesis (short)
% 2. "Related work", or intro++: research context, where the boundaries are

% Examiners will know about: PDEs, maybe handcoding

\chapter{Background and related work}

% TODO: \ref sections here
We first provide an overview of loop nest optimisations, techniques, and analyses that we have applied, with specific reference to the polyhedral model. % TODO: cite
This forms the basis and context for the entire report, and in particular the survey of related work, which composes the remainder of this chapter (Section~\ref{sec:survey}).

% TODO: grandiose
This project extends a well-established idea from compiler theory, \emph{tiling}, to another dimension (time) in Devito.
This has traditionally been a challenging problem, as evaluating data dependences efficiently is beset with difficulties.

% We have a tradeoff between computation and memory usage
% Big IDEA: can use more memory, less computation ("this really should be true")
% Project: optimise memory usage
% Why exciting: one step to proving the idea


\section{Loop tiling}
% TODO: mention that iteration spaces under consideration are (nice rectangular continuous) matrices

\subsubsection{Optimisations on loop nests}
The bulk of computation for finite difference methods lies in loops. % TODO: cite
Loop nest optimisations seek to transform a loop, possibly changing its execution order to use data locality, parallelism, or otherwise avoid unnecessary operations.

% TODO
\paragraph{Data locality}
Something about caches: yet another thing I don't know how to explain...

\subsection{Insight}
To exploit data locality, we must use data before it gets evicted from the cache; ideally, data is not loaded into the cache more than once.
This is a complex process \cite{lam91}; nevertheless reuse does occur within sufficiently small iteration spaces.
We therefore contrive small iteration spaces by partitioning the original space into smaller tiles (Figure~\ref{fig:tiled-space}).

\begin{figure}[h]
	\centering
	\textbf{[A nice picture of some tiles]}
	\caption{Tiles over an iteration space. Note that the tile size need not be the same in each dimension, or divide the extent of the iteration cleanly.}
	\label{fig:tiled-space}
\end{figure}

Loop tiling is also commonly known as \emph{blocking}, or perhaps less transparently \emph{strip-mine and interchange}, as tiling is typically achieved through these two transformations.\footnote{Tiling may also enable other transformations, such as loop-invariant code motion, which may not be appropriate when the extents of the iteration are too large.}

\subsection{Strip-mining}
Named after the mining practice, strip-mining involves dividing a dimension of the iteration space into strips (Figure~\ref{lst:stripmine-basic}).\footnote{However, you cannot divide a dimension into lateral strips, only sequential ones.}
By itself, strip-mining does not change the execution order; it is a gateway to further transformations.

\begin{figure}[h]
\begin{lstlisting}
for (int x = x_start + 1; x < x_end - 1; x++) {
  A[x] = B[x-1] + B[x+1];
}

for (int x_blk = x_start + 1; x_blk < x_end - 1; x_blk += x_blk_size) {
  for (int x = x_blk; x < min (x_end - 1, x_blk + x_blk_size); x++) {
    A[x] = B[x-1] + B[x+1]; // loop body unchanged
  }
}
\end{lstlisting}
	\caption{A regular loop, then strip-mined over the variable \texttt{x}. Offsets are used on \texttt{x\_start}, \texttt{x\_end} to prevent out-of-bounds accesses. The \texttt{min} function avoids the need for remainder loops, in case the tile (block) size does not evenly divide the extent of the iteration. We will abbreviate the variable names in further examples.}
	\label{lst:stripmine-basic}
\end{figure}

We will need more loops to perform an interchange.
Figure~\ref{lst:stripmine} illustrates a loop that has been strip-mined in two dimensions.

\begin{figure}[h]
	\begin{lstlisting}
for (int x_blk = x_s; x_blk < x_e; x_blk += x_bs) {
  for (int x = x_blk; x < min(x_e, x_blk + x_bs); x++) {
    for (int y_blk = y_s; y_blk < y_e; y_blk += y_bs) {
      for (int y = y_blk; y < min(y_e, y_blk + y_bs); y++) {
        A[x][y] = B[x][y] + B[x][y+1];
      }
    }
  }
}
	\end{lstlisting}
	\caption{Strip-mining a loop nest iterating over variables \texttt{x} and \texttt{y}. Offsets have been omitted here.}
	\label{lst:stripmine}
\end{figure}

% TODO: consider visualising the iteration space here

\subsection{Loop interchange}
\label{sec:interchange}
Loop interchange is based on the observation that a change in execution order does not change the correctness of a strip-mined program.
We will change the order of the loops to iterate over the tiles, then within them (Figure~\ref{lst:interchange}).

\begin{figure}[h]
\begin{lstlisting}
for (int x_blk = x_s; x_blk < x_e; x_blk += x_bs) {
  for (int y_blk = y_s; y_blk < y_e; y_blk += y_bs) {
    for (int x = x_blk; x < min(x_e, x_blk + x_bs); x++) {
      for (int y = y_blk; y < min(y_e, y_blk + y_bs); y++) {
        A[x][y] = B[x][y] + B[x][y+1];
      }
    }
  }
}
\end{lstlisting}
	\caption{The loop nest of Figure~\ref{lst:stripmine}, with the \texttt{x} and \texttt{y\_blk} loops interchanged.}
	\label{lst:interchange}
\end{figure}

This is valid when each point in the iteration space does not depend on the values calculated in the same iteration.
Therefore, one must be extremely careful that no data dependences cross boundaries between tiles; if they do, they must be permitted to cross only in one direction, and the tiles must be scheduled in that order.

\subsection{Polyhedral model}
[ How much do I want to discuss this, if at all?
It is very relevant, but I haven't seen polyhedra (or scanning of such) in the Devito codebase, and don't have a good grasp of them. ]


\section{Tiling in the time dimension}

\subsection{Motivation}
% TODO: vague; so what?
Many problems involving finite difference methods are computationally bounded, rather than bounded by memory throughput.
However, it is possible to reduce the operation count by exploiting the structure of expressions computed at the cost of increased memory pressure~\cite{fabio-memory}.
We are therefore interested to perform time-tiling to realise significant performance gains, possibly 27.5\% in Devito alone~\cite{dylan}.
This improvement is significant over the optimisation from tiling in all dimensions apart from time~\cite{pluto}.

\subsection{Skewing}
In Section~\ref{sec:interchange} we stated that interchange is valid when data dependences do not cross boundaries between tiles.
This is clear, as if there are no inter-tile dependences, the tiles can be executed in any order.

% TODO: "problems we discuss later": verify these are indeed discussed
% This could probably be clearer
\emph{Data dependences} occur when two statements reference a datum, at least one of which change it.
To preserve the dependence, we must preserve the order in which these statements are executed.
Figure~\ref{fig:dependence} illustrates how dependences may look in a (1-dimensional) iteration space similar to the problems we discuss later.

\begin{figure}[h]
	\centering
	\textbf{[Diagram with dependence arrows]}
	\caption{An iteration space with data dependences indicated by a forward arrow for a value derived from a dependence. It would not be valid to interchange loops over the \texttt{t} and \texttt{x} dimensions here.}
	\label{fig:dependence}
\end{figure}

We employ skewing to make the interchange valid (Figure~\ref{fig:dependence-skew}).
This solves the dependency problem~\cite{boulet98}.

% TODO: vague
\begin{figure}[h]
	\centering
	\textbf{[Diagram (skewed) with dependence arrows]}
	\caption{The same iteration space skewed by a factor of 2 in the \texttt{t} dimension. Note that the tiling is now valid, i.e.~we can execute the tiles in either dimension first.}
	\label{fig:dependence-skew}
\end{figure}


\section{Survey of related work}
\label{sec:survey}
The following sections...


\section{Halide}
Halide was conceived as a representation for image processing pipelines.
Many image processing algorithms are similar to stencils: Halide specifically deals with overlapping stencils; this overlap can be compared to iteration in the time dimension.

\subsection{Insight}
It is possible to separate image processing algorithms (``filters'') and their schedules~\cite{halide12}.
Optimisation for an architecture then becomes an exercise in optimising the schedule and not the filters, which are reduced to kernels.\footnote{See {https://github.com/halide/CVPR2015/blob/master/blur.cpp} for an example}
Halide is therefore a stencil compiler.

Modifying schedules is analogous to our loop optimisations: filters can be vectorised, tiled, interchanges are possible, etc.
Halide further provides an auto-tuner which estimates, among other things, arithmetic intensity of filters and loop transformations which Devito also employs~\cite{halide13,halide-sched}.
Part of its analysis examines the trade-off between additional computation and memory traffic.

\subsection{Applicability}
The problems Halide solves are very different to the difference equations we are concerned with.
However, the underlying natures of the solutions are very similar: use of stencil kernels, trade-off between redundant computation and memory pressure, etc.
Analogously to time-tiling, Halide is able to compute tiles across filters.
This is more general, different filters (hence kernels) may be applied at each step.

It may not be as crucial to use as sophisticated an auto-tuner in Devito, as kernels are applied repeatedly.
Domain-specific frameworks bring insight to a problem which general-purpose compilers may not possess; the separation of algorithm and schedule, while touted as novel, is essentially what every compiler applies.
In this case, the separation is explicit for the user and then hidden by the auto-tuner: an important note as this exposes a lower-level API, should one define an unusual filter.


\section{Pochoir}
Pochoir is a compiler for stencil computations focussed on utilising parallelism and multithreading.
Stencils are defined as C++ templates, from which the computations are generated.
Pochoir implements a two-phase compilation strategy: the first involves compilation with the Pochoir template library, which ensures compliance with the library. At this stage, one may debug the non-optimised code.
The second is compilation with the Pochoir compiler\footnote{The Pochoir compiler will also invoke the user's Cilk Plus compiler}, which is the optimisation phase~\cite{pochoir}.

\subsection{Insight}
\paragraph{Cache-oblivious algorithms}
These seek to eliminate tuning of cuts based on cache properties including cache sizes or replacement policies, reasoning that the correct cache-oblivious algorithm will achieve (asymptotically) the same performance~\cite{frigo-cacheoblivious}.

Pochoir uses a cache-oblivious algorithm based on parallel cuts.
These \emph{hyperspace} and \emph{time cuts} decompose the iteration space (``zoid'') into smaller spaces recursively;
they are chosen to improve parallelism while maintaining cache efficiency~\cite{frigo-cacheoblivious-alg}.

Thanks to cut dependence analysis, the resultant trapezoids can span iterations of a time loop.

\subsection{Applicability}
The Cilk Plus framework, which Pochoir uses, is intended to produce optimal scheduling for parallel tasks, and cache-oblivious algorithms may be optimal up to a constant factor.
Nevertheless, significant speedup can occur with \emph{cache-aware} algorithms, which employ tuning for multiple levels of cache~\cite{kowarschik-cacheaware}.
This is especially significant to domain specialists who are experimenting and changing models, or those who are performing stencil computations over large iteration spaces.

% TODO: vague
Additionally, the Cilk Plus framework is in the process of deprecation~\cite{cilkplus-migrate-web}, and Pochoir is not presently maintained.
While the concepts behind it may be sound and applicable in specific circumstances, it would be unsuitable to integrate with Devito.


\section{YASK}
\emph{Yet Another Stencil Kernel} is a framework that transforms and optimises stencil kernels written in C++, especially targeting the Xeon Phi platform~\cite{yask-web}.
Like Pochoir, YASK provides C++ templates for stencils.
Similarly to Halide, it uses a genetic-algorithm based search for its auto-tuner.

It is intended to function both as a platform for domain specialists to experiment with (higher-level) optimisations, as well as for the compilation of high-performance kernels.

\subsection{Insight}
Stencil kernels rapidly grow complicated.
Once optimisations have been applied (possibly through a specialised stencil compiler) to stencils, general-purpose compilers are less able to explore the trade-offs of further optimisation which they would ordinarily apply, such as parallelism.
YASK aims to solve this by, among other things, implementing a two-stage compiler (stencils and loops) and tuning for the execution environment~\cite{yask-paper}.

In contrast to polyhedral research compilers such as PLUTO~\cite{pluto}, YASK has a specific focus on combining optimisations such as vector-folding~\cite{yount-vector} with the loop optimisations which they perform.

\subsection{Applicability}
YASK was originally created to implement vector folding, a technique which simultaneously takes advantage of SIMD instructions and reduces memory bandwidth usage.
This is especially relevant in Devito, which has the transformation of arithmetically intensive computations into memory intensive computations as a basis.

Further, with its emphasis on integrating different optimisations, rather than investigating them separately, YASK is a practical tool for a workflow involving stencils.
There would be no need to apply a stencil compiler, then a polyhedral compiler, without the guarantee that the latter would understand and be able to build open the complexities introduced by the former.

Devito is in the process of integrating YASK as a compilation backend.
We will explore the motives for this in Section~\ref{sec:devito}.


\section{Firedrake}
\begin{itemize}
	\item FEniCS: separate usage and implementation of FEM
	\item Firedrake: separate discretisation of operators and parallel execution (kernels vs calculations?) \cite{firedrake}
	\item Also lower level access: custom kernels, direct access to data structures
	\item More general than Devito?
\end{itemize}


\section{Devito}
\label{sec:devito}
Devito~\cite{devito} is a domain-specific language and code generation framework for finite-difference method computations~\cite{devito-web}.
Its main purpose is to build solvers for differential equations from high-level mathematical expressions written using the symbolic library \emph{SymPy}.

\begin{itemize}
\item Transform expression into stencils
\item Construct stencil equations
\item Generate code (either natively or YASK, etc.)
\item For stencil applications (not every finite-difference problem)
\item Lower level API (recall: sparse point interpolation)
\end{itemize}


\section{Summary}
