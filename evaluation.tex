\documentclass[thesis.tex]{subfile}

\chapter{Evaluation}
\label{ch:evaluation}

This chapter is devoted to the performance evaluation of our implementation of time-tiling in Devito.
It is organised into a number of sections:

\wip{Update this when done}
\begin{itemize}
	\item First, we recall the motivation of this project, and the objectives of our evaluation (Section~\ref{sec:eval-objs}).
	\item We then discuss the restrictions that time-tiling imposes on our use of Devito, and the considerations that it warrants (Section~\ref{sec:time-tiling-details}).
	\item Next, we present the test methodology we have adopted (Section~\ref{sec:test-method}), and introduce the \emph{roofline model} (Section~\ref{sec:roofline-intro}), which is widely used to understand the performance of stencil calculations.
	We also discuss the parameters varied in the tests (Section~\ref{sec:eval-params}).
	\item Sections~\ref{sec:perf-laplace} and~\ref{sec:perf-awe} examine the performance of two families of stencils, generated by the Laplace and acoustic wave equation operators respectively.
	\item Finally, we discuss limitations of our performance testing and consider further work in evaluation (Section~\ref{sec:further-eval}).
\end{itemize}


\section{Objective}
\label{sec:eval-objs}

The motivation for this project is to reduce computational runtime by exploiting data locality between time iterations through time-tiling.
We have described the motivation and investigated tools which have achieve performance gains from the technique.
It had previously been shown that Devito benefits from reductions in runtime of up to 27.5\% with time-tiling using CLooG~\cite{dylan}.

Chapter~\ref{ch:implementation} described our implementation of time-tiling in Devito.
The objectives of this evaluation are as follows:

\begin{itemize}
	\item Measure the performance gain against non-tiled and spatially-tiled computations;
	\item Verify any requirements to perform time-tiling effectively;
	\item Determine procedures and heuristics to identify the best-performing parameters for time-tiling;
	\item Additional verification of correctness, and margin of error introduced against non-tiled code\footnote{For example, due to non-associativity of floating-point arithmetic.} if any.
\end{itemize}


\section{Details for evaluating time-tiling}
\label{sec:time-tiling-details}

As time-tiling has been implemented within Devito, there is no need for any external tool such as a polyhedral compiler.
Nevertheless, the following topics warrant careful consideration when applying and analysing time-tiling.

\subsection{Time-buffering}
\label{sec:time-buffering}

% Time buffering and save=n>2*time tile size (a nice diagram!)
Time-buffering is a memory-saving technique.

\begin{figure}[!ht]
\begin{lstlisting}
for (int t = t_s; t < t_e; t++)
  for (int x = x_s; x < x_e; x++)
    A[t][x] = A[t-1][x] + A[t-2][x] + ... + A[t-n][x];
\end{lstlisting}
	\caption{A stencil with a value depending on data in the previous \(n\) time iterations. \(n\) is usually small compared to the problem domain, (\texttt{t\_e - t\_s + n}) here.}
	\label{lst:buffer-eg}
\end{figure}

A stencil may only have dependencies on data from finitely many previous time iterations.
Consider a stencil with a data dependence on the last \(n\) time iterations (Figure~\ref{lst:buffer-eg}).
It is clear that whenever \(t > n\), data from the 0-th time iteration is no longer required, and can be overwritten.

When space-tiling in Devito, each time iteration only begins once the previous iteration has finished.
Therefore, we only need storage for \(n+1\) time iterations of data: the current iteration being computed; and the previous \(n\) iterations, its dependencies.

As we have not implemented the calculation for a correct time buffer size in Devito, we did not use time buffering for the Laplace operator stencils, and manually specified a buffer size for the acoustic wave equation operator stencils.
Nevertheless, it is straightforward to establish bounds on the size of a time buffer.
It is clear that for time-tiling to perform better than spatial tiling, at least \(n+2\) time iterations must be stored.\footnote{It is a simple exercise that time-tiling needs exactly \(n+t\) time iterations of storage, where \(t\) is the size of a time tile.}


\subsection{Auto-tuner iterations}
% Further prereqs to use the AT
Previously covered in Section~\ref{sec:autotune}, the Devito auto-tuner experimentally searches for tile sizes achieving the lowest runtime.
To do this, it needs to store some time iterations of computations: this value is governed by a parameter.

For its results to be meaningful, we need to compute enough time iterations to distinguish between large time tile sizes.
Without time-tiling, a fairly small number of time iterations (4) sufficed for auto-tuning.
In our evaluation, we decided that the largest desirable time tile size was 16, to which we set the parameter.

\subsection{Time-tiling parameters}
Time-tiling provides more parameters: a valid skewing factor, and a tile size for the time dimension.
The tile size search was integrated into the auto-tuner, as it already had functionality to search for spatial tile sizes.

It was decided to try skewing factors by hand, as their validity would depend on the stencil (Section~\ref{sec:bg-skewing}), and we wished to find a heuristic for the skewing factor resulting in the lowest runtime.
We have found that the minimum skewing factor produces the lowest runtime (Section~\ref{sec:eval-skewing-effect}).

\section{Arithmetic intensity under time-tiling}
\label{sec:arithmetic-intensity}

Recall that \emph{arithmetic intensity} is defined to be the number of floating point operations performed per byte.
Time-tiling is an optimisation to improve the reuse of cached data, effectively increasing the arithmetic intensity of a stencil, as data needs to be fetched from memory less frequently.

In this section, \(d_t\) represents the time dimension and \(d_i (i=1,2,\cdots)\) represent a spatial dimension;
\(D_i\) represents the extent of dimension \(d_i\), or \(D_t\) the extent of the time dimension;
\(r_i\) the spatial radius of the stencil in dimension \(d_i\), \(r_t\) the distance of the time dependence;
\(t_i\) the chosen tile size in dimension \(d_i\), \(t_t\) for the time tile size;
and \(\Omega\) represents the size of the cache.

\subsection{Arithmetic intensity estimator in Devito}
Suppose a stencil requires data from the last \(r_t\) time iterations.
Devito reports arithmetic intensity as `operational intensity', and calculates it as follows:

\begin{description}
	\item[Non-tiled code] Arithmetic intensity is calculated from the definition, assuming that data that has been loaded into the cache would \emph{not} need to be re-loaded in the same time iteration.
	In reality, with a sufficiently large iteration space, each byte would have to be loaded into cache more than once for each time iteration.
	The measure therefore \emph{overestimates} the number of floating point operations per byte loaded from memory and hence true arithmetic intensity.
	In the graphs later in this chapter, an overestimate results in a \emph{right shift} of a data point from its true location.

	\item[Space-tiled code] Again, Devito assumes data need only be loaded into the cache once per time iteration, hence would be used fully before being evicted, calling this scheme `compulsory memory traffic'.
	For each time iteration, this requires the previous \(r_t\) time iterations of data to be loaded from memory.
	This produces the same figure for arithmetic intensity as the measure for non-tiled code above.
	Since the dependencies of tiles overlap in previous time iterations, with a sufficiently large iteration space, some dependencies will need to be loaded into cache more than once (assuming at least two spatial dimensions with non-zero space order).\footnote{This is fairly simple to see. Ignore all but two spatial dimensions with non-zero space order, and suppose otherwise for a contradiction. Arbitrarily choose a finite cache size of \(\Omega\) floating-point numbers, and call our spatial dimensions \texttt{x}, \texttt{y} with dimension extents \(x, y\) respectively. W.l.o.g.~\(x \le y\) and that the stencil has space order \(d>0\) in both dimensions (take the minimum). Now we need \(xd \le \Omega\), since minimising dependency overlap along the \texttt{x} dimension demands that we calculate the first \texttt{x} `row' before any other \texttt{x}-tiles. But we can choose \(x > \Omega / d\).}
	Thus this measure also \emph{overestimates} arithmetic intensity, but to a smaller extent than with non-tiled code.
	Later, we explore the possibility of a tighter bound.
\end{description}

Remark: later, we will see that it is preferable to overestimate the arithmetic intensity of a stencil computation than underestimate it, and we provide arguments for why the measures stated in this section are useful and fairly realistic.
This will be explained in detail when studying the roofline model in Section~\ref{sec:roofline-intro}, as it requires other ideas that have yet to be introduced.

\subsection{Estimating arithmetic intensity under time-tiling}
We need to establish a new measure for arithmetic intensity under time-tiling, preferably one compatible with the existing measure under spatial tiling.
We consider the following statements to follow naturally from Devito's calculation of arithmetic intensity under spatial tiling.

\begin{itemize}
	\item Analogously to space-tiling, we assume that data will be used fully before being evicted from cache.
	\item If \(t\) is the time tile size, we can calculate \(t\) time iterations of data from \(n\) previous time iterations loaded into the cache, as opposed to calculating 1 time iteration from the same data.
	\item Thus we have performed \(t\) times as many floating-point operations on it.
\end{itemize}

A natural estimator for the arithmetic intensity of a stencil computation under time-tiling might be the arithmetic intensity of the same computation under spatial tiling multiplied by the size of the time tile used.

This is consistent with the measure under spatial tiling, since a spatially tiled loop is similar a time-tiled version of the loop under a (legal) interchange of the time and spatial tile loops.
This would also result in an overestimate; the next section explores the magnitude of this overestimate under spatial and time-tiling.

\wip{Section TODO}
We will refer to this estimator as the \emph{naive estimator}, which only requires information about the stencil.
Now we will explore tighter bounds assuming ideal scheduling; later in our analysis (Section TODO) we will demonstrate why they are necessary.

\subsection{Tile boundaries determine cache reuse}
Recall that in spatial tiling, we contrive small iteration spaces (`tiles') such that the data dependencies from the previous time iteration could fit within the cache.
Therefore, the internal volume of a tile need only be transferred from memory once (Figure~\ref{fig:tile-reload}).
However, there is no such guarantee for the boundary region of a tile.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}
	\draw[xstep=3cm,ystep=1.5cm,black,thick] (0,0) grid (15,6);

	\foreach \x in {1,2,3,4}
		\fill[pattern=north west lines,pattern color=black] (\x*3-.2,0) rectangle (\x*3+.2,6);
	\foreach \y in {1,2,3}
		\fill[pattern=north west lines,pattern color=black] (0,\y*1.5-.2) rectangle (15,\y*1.5+.2);
	
	\foreach \x in {0,1,2,3,4}
	\foreach \y in {1,2,3,4}
		\pgfmathsetmacro\seq{\x * 4 + \y}
		\node at (3*\x+1.5,1.5*\y - 0.75) {\pgfmathprintnumber{\seq}};

	\draw[thick,->] (0,0) -- (15.2,0) node[right]{\(d_1\)};
	\draw[thick,->] (0,0) -- (0,6.2) node[above]{\(d_2\)};
	\end{tikzpicture}
	\caption{Tiles over a 2D iteration space. The clear regions need only be loaded once, but data in the hatched regions may need to be loaded multiple times, depending on the cache size. We will call the hatched region the \emph{tile boundaries}.}
	\label{fig:tile-reload}
\end{figure}

Consider a (2-dimensional) tiling in which we iterate over the \(d_1\)-tiles, then the \(d_2\)-tiles, or as the order indicated in Figure~\ref{fig:tile-reload}.
In this situation, the tile boundaries between \(d_2\)-tiles such as 1, 2 may fit within the cache; if so it is clear that none of these boundaries will need to be loaded twice (apart from the intersections with the \(d_1\)-boundaries).
Call this, the common boundary between two iterations of a \(d_2\)-tile loop, a \(d_2\)-face.
Similarly, if the boundary between \(d_1\)-rows fits within the cache, such as the boundary between tiles 1--4 and 5--8, then it is a possibility that the data within these boundaries need not be loaded twice.
Likewise, call this boundary a \(d_1\)-face, and in general call the common boundary between two iterations of the \(d_i\)-tile loop a \(d_i\)-face, with size \(F_i\).

Now consider the \(n\) dimensional case, first iterating over the \(d_1\)-tiles, then the \(d_2\)-tiles, and so on.
We make the following claim:

\begin{framed}
	If \(i \le n\) and \(F_{i} \ge \Omega\), then data of equivalent size to the contents of \emph{every} \(d_j\)-face must be loaded into the cache at least twice, for \(1 \le j < i\).
\end{framed}

For proof, we demonstrate the fact for the \(d_{i-1}\)-faces over the \(d_{i-1} d_i\)-plane; the rest by backwards induction.

\begin{figure}[ht]
	\centering
	\begin{tikzpicture}
	\draw[xstep=3cm,ystep=1.5cm,black,thick] (0,0) grid (15,6);

	\fill[pattern=north east lines,pattern color=black] (0,4.3) rectangle (3,4.7);
	\node at (1.5,5) {(A)};

	\fill[pattern=north west lines,pattern color=black] (5.8,1.7) -- (5.8,6) -- (6.2,6) -- (6.2,1.3);
	\node at (6.5,3.75) {(B)};
	
	\fill[pattern=north east lines,pattern color=black] (2.8,1.7) -- (5.8,1.7) -- (6.2,1.3) -- (3.2,1.3);
	\node at (4.5,2) {(C)};

	\fill[pattern=north west lines,pattern color=black] (2.8,0) -- (2.8,1.7) -- (3.2,1.3) -- (3.2,0);
	\node at (2.45,0.75) {(D)};

	\draw[thick,->] (0,0) -- (15.2,0) node[right]{\(d_{i-1}\)};
	\draw[thick,->] (0,0) -- (0,6.2) node[above]{\(d_i\)};
	\end{tikzpicture}
	\caption{Tiles in the \(d_{i-1} d_i\)-plane. We consider iterations crossing the \(d_2\)-faces corresponding to regions A and C.}
	\label{fig:tile-zigzag}
\end{figure}

Suppose that a \(d_i\)-face (region A in Figure~\ref{fig:tile-zigzag}) cannot fit into the cache, i.e.~\(F_i > \Omega \).
Observe that region C (opposing hatch pattern to B, D) has the same size as region A, \(F_i\), and suppose some of the contents of a \(d_{i-1}\)-face (equal to regions B + D) do not need to be loaded into cache, and that we are evaluating the \(d_i\) tile across the C-boundary.
But region C is larger than the cache, so we cannot accommodate C alongside any points from B, D.
Thus data equivalent to the combined areas of B, D must be loaded from memory at least twice, and the claim follows.

\subsection{Establishing a tighter bound}
Let \(B_i\) be the union of \(d_i\)-faces.
It is a fact that the \(d_i\)-faces are distributed proportionally across the \(d_i d_j\)-plane whenever \(i \ne j\); in particular:

\[ \frac{\left| B_i \cup B_j \right|}{\prod_{k=1}^n D_k} = \frac{\left| B_i \right| + \left| B_j \right|}{\prod_{k=1}^n D_k} - \frac{\left| B_i \right| \times \left| B_j \right|}{\left(\prod_{k=1}^n D_k\right)^2} \]

All that remains is to find expressions for \(F_i, \left|B_i\right|\). Have:

\[ F_i = 2 \left(\prod_{j=1}^{i-1} t_j \right) r_i \left(\prod_{k=i+1}^{n} D_k \right) \]

since we need to account for the full extent of each lower dimension in the loop structure, the width of overlap in the \(i\)-th dimension (\(2 r_i\)), and the tile sizes in the higher dimensions; and

\[ \left|B_i\right| = 2 \frac{r_i}{D_i} \times \floor*{\frac{D_i}{t_i}} \]

as \(2\sfrac{r_i}{D_i}\) is the proportion of each \(d_i\)-face to \(D_i\), and \(\floor*{\sfrac{D_i}{t_i}}\) is the number of \(d_i\)-faces.

Finally, let \(B = B_1 \cup B_2 \cup \cdots \cup B_{i-1}\) for \(F_i \ge \Omega > F_{i-1} \) whenever \(1 < i < n\); if there is no such \(i\), then let \(B = \varnothing \).
Then divide the original arithmetic intensity estimate by the following to get a tighter bound:

\[ 1 + \frac{|B|}{\prod_{k=1}^n D_k} \]

Note that this method will only yield a tighter bound if \(F_i \ge \Omega\) when \(i > 1\).
If only \(F_1 > \Omega \), we can use a variation of this algorithm.
We have that for every \(d_1\)-face, \(F_1 - \Omega\) points do not fit into the cache, and have \(\floor*{\sfrac{D_1}{t_1}}\) \(d_1\)-faces.
Then consolidating these points we use:

\[\left|B\right| = \left(F_1 - \Omega\right) \times \floor*{\frac{D_1}{t_1}} \]

\subsection{Generalisation to time-tiling}
As a summary, the previous sections gave an algorithm to find additional memory transfer on tile boundaries within a single time iteration, under spatial tiling.
This tile boundary excess transfer is of the same magnitude in each time iteration of a time tile.
Hence we only multiply the figure by the time tile size.
Do note that the naive spatial tiling estimator is first multiplied by the time tile size to establish the naive time-tiling estimator.
Then divide by:

\[ 1 + \frac{|B| \times t_t}{\prod_{k=1}^n D_k} \]

We will use the above estimators for arithmetic intensity under both spatial and time-tiling.
While this has the disadvantage of potentially decreasing the arithmetic intensity of a stencil under spatial tiling from non-tiled code, we will not be analysing the performance of non-tiled code in relation to the roofline model detailed in Section~\ref{sec:roofline-intro}.

To summarise, the required data to calculate the arithmetic intensity under time-tiling are:

\begin{enumerate}
	\item Extents of the iteration space (\(D_t, D_1, D_2, \cdots\))
	\item Stencil spatial and time dependences (\(r_t, r_1, r_2, \cdots\))
	\item Chosen tile sizes (\(t_t, t_1, t_2, \cdots\))
	\item Size of the cache (\(\Omega\))
\end{enumerate}

Note that due to space constraints, we have not reported the auto-tuned tile sizes in our tables giving the arithmetic intensity data.
This data, along with complete logs of program output and auto-tuner results, is fully available in the project archive.

\subsection{Improving the bounds further}
Note that the spatial tiling bound given can be improved further, as we did not consider need to partially re-load data from the \(d_i\)-faces.
This would have a corresponding effect on the time-tiling bound.
However, we felt this would add significant complication for meagre benefit.

Additionally, note that the cache would (at times) need to not only contain a \(d_i\)-face, but also \(d_{i+1}, \cdots d_{n}\)-faces, by a similar argument to the one presented with Figure~\ref{fig:tile-zigzag}.
Therefore it may be sufficient to fulfil \(F_i + F_{i+1} + \cdots + F_n > \Omega\).

However, since the extent of any dimension is likely to dwarf any tile size, this is unlikely to be relevant; in practice with 3 spatial dimensions, the auto-tuned tile sizes mean that only the \(F_1 > \Omega \) case is relevant.
The method is nevertheless crucial for the generalisation to time-tiling.


\section{Testing methodology}
\label{sec:test-method}

Realistic test cases vary from those that are more memory intensive to those that are more computationally intensive on a given hardware configuration.
Under the former regime, computational (arithmetic) intensity is fairly low, and the CPU uses data faster than it can be transferred from memory; in the latter case, data can be transferred more rapidly than it can be utilised.

A key premise of Devito is that arithmetic intensity can be decreased at the cost of higher memory pressure, by manipulating expressions~\cite{fabio-memory}.
Time-tiling reduces memory pressure by increasing reuse of cached data before it is evicted.\footnote{However, this effectively increases the arithmetic intensity, as discussed in this chapter.}
Accepting the premise that arithmetic intensity can be reduced sufficiently, time-tiling can be used to full effect in reducing memory pressure.\footnote{See Section~\ref{sec:roofline-intro} (``Roofline model'') for more detail.}
Therefore, the most relevant test cases to time-tiling are those which are bound by memory throughput.

\subsection{Hardware and software environment}
Evaluation was performed on a machine equipped with a single Intel Xeon\textregistered\ E5-2470 operating at 2.30 GHz, with 8 cores and 16 threads, 20MB of L3 cache, and 64 GB of DRAM.
It ran Ubuntu 16.04 LTS, with all running services required either for the operating system or our evaluation, to minimise external effects on runtime.

To ensure a realistic testing environment and utilise all the available resources, the following hold throughout the experiments:

\begin{itemize}
	\item OpenMP\footnote{OpenMP is a standard API used for compilers to implement parallelism~\cite{openmp-spec}.} directives enabled in Devito. Indicates that a loop should be computed in parallel (typically the body of the incremental time loop).
	\item OpenMP environment variable to utilise all 16 available threads.
	\item OpenMP environment variable not to migrate threads (``thread pinning''), as well as allocate threads to different cores. Thread migration incurs a significant performance overhead, and parallelism would not help if all threads executed in serial on one core.
	\item Usage of the Intel C Compiler, \texttt{icc}.
	\item Devito enables the highest level of compiler optimisation and parallelism in the compiler by default.
\end{itemize}

\subsection{Use of auto-tuner}
% Usage of AT -- parameters (skewing factor, time and space tile sizes)
We wanted to experiment with tile sizes optimal under time-tiling, as they are not easily predicted from those optimal for spatial tiling or cache size~\cite{lam91}.
Therefore, the extended Devito auto-tuner (Section~\ref{sec:autotune}) was used to explore as many plausible tile sizes combinations as possible.

As detailed above, experimentation on the skewing factor was done manually.
An exhaustive search was performed, as the space was relatively small.
Further, finding a heuristic for optimal skewing factors is an objective of our evaluation.

\subsection{Functional correctness}
\label{sec:eval-func-corr}

In addition to new test cases, to build confidence in correctness of the newly-implemented skewing and tiling transformations, each application of time-tiling was numerically verified against a non-tiled computation.

In all experiments, the results were discovered to be equal.\footnote{We refer to equality under floating-point comparison; this is \emph{bitwise equality}.}
Since floating-point arithmetic is non-associative, the natural implication is that the resulting value in each field was reached through the same expressions, although the computations had been re-ordered.
Additional checks were used to determine that the results were not merely zeroes, or diverging to infinity.

\subsection{Experimentation and reporting of runtimes}
Wherever runtimes have been collected in this evaluation, the reported figure will be the \emph{minimum} of the runtimes collected in trials.
This is taken as most representative, as any noise on the testing machine is minimised, since outside factors can only increase the runtime of our computations.

Using the Laplace stencils, the auto-tuner was run for at least three trials.
The most tile size combination with the overall lowest runtime was selected, and run for a further seven trials, thus we report the minimum of 10 trials.
This obviated the need to run auto-tuning for each data point, reducing the time needed to obtain a data point by 65\%, or about a week of machine time.

For the acoustic wave equation stencils, we used the auto-tuner for each of the 10 trials run for each data point.
Thus the reported figure is the minimum of 10 auto-tuned trials.


\section{Roofline model}
\label{sec:roofline-intro}

The roofline model describes how arithmetic (or \emph{operational}) intensity kernel affects its performance on a given system.
In particular, it gives upper bounds for performance based on memory bandwidth and CPU performance, and describes the bottlenecks that a program would encounter based on its arithmetic intensity~\cite{roofline}.
The model states that as arithmetic intensity increases, performance increases at a rate determined by the memory bandwidth, until it reaches the performance limit (in Flops, floating-point operations per second) of the processor.

\subsection{Bounds of the test machine}
The Sandy Bridge architecture supports execution of up to 16 single-precision floating point operations per cycle, giving a theoretical maximum of 294.4 GFlops.\footnote{Calculated as 16 floating-point operations/cycle \(\times 2.3 \times 10^9\) cycles/sec/core \(\times\) 8 cores (on a single-node machine) \(= 294.4\) GFlops.
\\\wip{Fabio: 2.3GHz is the `processor base frequency', which I suspect is still not what you mean? Pl. confirm.}}
The \emph{LINPACK} benchmark~\cite{linpack}, highly optimised and likely to perform faster than any stencil we evaluate, achieves a maximum of 131 GFlops on this machine; it is standard practice to double this figure to obtain the maximum for single-precision floating-point operations, giving a practical bound of 262 GFlops in our test scenarios.
In practice, few programs begin to approach the performance achieved by the \emph{LINPACK} benchmark.
The \emph{STREAM} benchmark~\cite{stream} indicates that the peak memory bandwidth of the machine is 17.3 GB/s.

\subsection{Arithmetic intensity and cache reuse}
Figure~\ref{fig:roofline-benchmark} shows and explains the bounds of a stencil of a given arithmetic intensity.
A given stencil computation can be plotted as a point on the graph, determined by its GFlops achieved, which we measure at runtime, and its inherent arithmetic intensity.
Clearly, these are strict bounds on the performance of a stencil.

\begin{figure}[!ht]
\centering
\begin{tikzpicture}
\begin{axis}[
legend style={at={(0.95,0.05)},anchor=south east},
xlabel={Arithmetic intensity},
ylabel={GFlops achieved},
domain=0.4:96,
xmode=log,
log basis x={2},
ymode=log,
log basis y={2},
log ticks with fixed point,
]
% roofline
\addplot [domain=0.46:15.15,name path=A] {17.3*x};
\addplot [domain=15.15:80] {262.01};
% boundary
%\path[name path=X] (axis cs:15.5,8) -- (axis cs:15.5,262.01);
\addplot +[mark=none,dashed,thick,name path=X] coordinates {(15.15, 8) (15.15, 262.01)};
\addplot[gray, pattern=north west lines] fill between [of=A and X];
\end{axis}
\end{tikzpicture}
\caption{Roofline graph for the test machine. Performance of any stencil (GFlops) of given arithmetic intensity cannot exceed the solid lines plotted. A stencil falling into the hatched region (arithmetic intensity < 15.15) will be bounded by memory bandwidth indicated by the sloped line, and those in blank region (arithmetic intensity > 15.15) are bounded by processor performance, the horizontal line. These two solid lines are the \emph{roofline}.}
\label{fig:roofline-benchmark}
\end{figure}

We previously suggested that it was preferable to overestimate arithmetic intensity than underestimate it.
As we can see from the figure, if we permit ourselves to underestimate arithmetic intensity, a point could lie \emph{above} the roofline, contradicting the model.
Therefore, we must not underestimate arithmetic intensity.

Recall that the objective of time-tiling is to maximise cache reuse by exploiting data locality between time iterations.
As previously argued, if a computation is bounded by memory throughput (hence in the shaded region), improving effective throughput through more effective cache usage could be reasonably argued to decrease the runtime.
From the previous discussion (Section~\ref{sec:arithmetic-intensity}), we established that tiling transformations effectively increase the arithmetic intensity of a stencil computation, resulting in a rightward shift of a data point on this graph.

We see from the diagram that such a rightward shift starting from any point in the shaded region increases the performance bound under the roofline.
Therefore, we seek to demonstrate that this is accompanied by an upward shift (together a diagonal shift) of the performance of a memory-bounded stencil computation.
In particular, we hypothesise that the performance increase of stencils that are more memory bounded (lower arithmetic intensity) will yield the greatest benefit from time-tiling.


\section{Test parameters}
\label{sec:eval-params}

\paragraph{Skewing factor}
The skewing factor was varied to understand the relationship between skewing factor and runtime.
In particular, we wished to determine if the minimum legal skewing factor would result in the minimum runtime as hypothesised.

\paragraph{Space order}
The space order of the computation determines the precision of the result.
In solving differential equations, this is the order of the approximation, beyond which smaller terms are ignored.
A higher space order results greater precision, stencil radius, and minimum skewing factor, and results in a higher arithmetic intensity, which we study.

\paragraph{Time tile size}
For each operator, we report two sets of figures: a set of auto-tuned results with any time tile size and varying skewing factors; and a set with varying time tile sizes, to inform separate analyses on skewing factors and time tile sizes.

\paragraph{Domain size}
The size of the domain is the product of all four dimensions in the simulation.
As memory was limited to 64GB needed to store both time-tiled and non-tiled results for numerical verification, we decided to use shorter time dimensions, maximising the spatial dimension size for realism.
We justify this choice reasoning that runtime should be proportional to the number of time tiles executed.\footnote{This was verified using smaller spatial dimensions.}
Therefore, we chose time dimensions 16 or 32, as these are small multiples of the time tile size.
To ensure the results are valid, we need to ensure that a single time iteration well exceeds the size of the cache.


\section{Performance of the Laplace operator}
\label{sec:perf-laplace}

\subsection{Application of the operator}
The Laplacian is the operator giving the divergence of the gradient of a scalar function, commonly used in mechanics.
In our evaluation, we used three spatial dimensions and a time dimension, with a deterministically generated input domain for numerical verification.
The input domain was chosen to avoid divergence of values, again for the purposes of numerical verification.

We previously stated that we were studying a family of stencils generated by this operator.
Devito makes it straightforward to generate stencils of varying space order, otherwise a non-trivial task; we have considered the Laplace operator with space orders 2, 4, 8, and 16.
% Sample code from apply.py
% Insert perf1.py into appendix (invocation of the operator, testing rigour)

\subsection{Results}
Two grid sizes, \(32 \times 500^3 \) and \(16 \times 600^3 \), were chosen to comply with our memory limit.
Table~\ref{tab:laplace-results} shows the runtimes arising from running time-tiling compared to spatial tiling under the Laplace operator.
Figure~\ref{fig:laplace-graph} provides the corresponding graph for the \(16 \times 600^3 \) grid; the results and graphs for both grids are similar.

\begin{table}[p]
\centering
\begin{tabular}{rr|cccc|cccc}
\toprule
& Grid size & \multicolumn{4}{c}{\( 32 \times 500^3 \)} & \multicolumn{4}{c}{\( 16 \times 600^3 \)} \\
& Space-order & 2 & 4 & 8 & 16 & 2 & 4 & 8 & 16 \\
\midrule
N & \footnotesize runtime (s) & 6.121 & 7.572 & 10.65  & 16.941 & 5.189 & 6.402 & 9.026 & 14.87 \\
S & \footnotesize runtime (s) & 3.964 & 3.760 & 4.060 & 5.778 & 3.489 & 3.376 & 3.684 & 4.980 \\
% & tile size & 32,64 & 128,8 & 128,8 & 16,16 & 32,40 & 32,32 & 8,64 & 16,16 \\
T & \footnotesize runtime (s) & 2.939 & 2.957 & 3.762 & 5.718 & 2.710 & 2.616 & 3.288 & 4.814 \\
& \footnotesize decrease (\%) & 25.9\% & 21.4\% & 7.34\% & 1.04\% & 22.3\% & 22.5\% & 10.8\% & 3.33\% \\

\midrule
(t,8) & \footnotesize runtime (s) & 3.348 & 3.257 & 3.762 & 5.718 & 3.089 & 2.966 & 3.341 & 4.814 \\
(t,4) & \footnotesize runtime (s) & 3.114 & 3.090 & 3.764 & - & 2.844 & 2.811 & 3.288 & - \\
(t,2) & \footnotesize runtime (s) & 2.956 & 2.957 & - & - & 2.788 & 2.616 & - & - \\
(t,1) & \footnotesize runtime (s) & 2.939 & - & - & - & 2.710 & - & - & - \\
\bottomrule
\end{tabular}
\caption{Runtimes (minimum of 10 trials) from using the Laplace operator. N, S, T represent minimum runtimes without tiling, with spatial tiling, and with time-tiling respectively. (t,\(k\)) indicates results for time-tiling with a skewing factor of \(k\); T indicates the minimum of these. `-' denotes invalid skewing factor. Decrease is from spatial tiling to time-tiling.}
\label{tab:laplace-results}
\end{table}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{axis}[
width=0.7\textwidth,
legend style={at={(0.05,0.95)},anchor=north west},
xlabel={Space order},
ylabel={Runtime(s)},
ytick distance=2,
]
\addplot table [x=sp,y=run,col sep=comma] {data/laplace-nt600.csv};
\addplot table [x=sp,y=run,col sep=comma] {data/laplace-sp600.csv};
\addplot table [x=sp,y=run,col sep=comma] {data/laplace-tm600.csv};
\legend{Non-tiled,Space-tiling,Time-tiling}
\end{axis}
\end{tikzpicture}
\caption{Non-tiled, spatially tiled and time-tiled runtimes, with a grid size of \(600^3\) and 16 time iterations using stencils from the Laplace operator. The runtimes under tiling converge as the space-order increases.}
\label{fig:laplace-graph}
\end{figure}

As a preliminary, we note that both spatial and time-tiling yield much lower runtimes than non-tiled code.
This shows that non-tiled code is much less efficient than tiled code, highlighting the importance of the tiling transformation and data locality.

Immediately evident is that the benefit from time-tiling rapidly tapers as the space-order increases, with stencils with larger radii.
There are two likely (related) explanations for this: an increase in the amount of data needed to compute any one tile, and an increase in arithmetic intensity, slowing the rate of data consumption, making memory bandwidth less relevant.

\begin{table}[p]
\centering
\begin{tabular}{cr|c|c|ccccc}
\toprule
& & N & S & \multicolumn{5}{c}{T; time tile size} \\
Space-order & &   &   & 1 & 2 & 4 & 8 & 16 \\
\midrule
16 & \footnotesize GFlops & 31.22 & 93.24 & 94.19 & 95.34 & 96.44 & 93.63 & 94.14 \\
%\multicolumn{2}{r|}{\footnotesize arith. intensity} & 15.8 & 14.0 & 14.0 & 31.6 & 63.2 & 126 & 253 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 15.8 & 14.0 & 14.0 & 25.1 & 41.6 & 62.0 & 82.1 \\
\midrule
8 & \footnotesize GFlops & 30.22 & 74.06 & 75.89 & 78.88 & 81.40 & 82.84 & 82.97 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 9.29 & 9.29 & 9.29 & 18.6 & 37.2 & 74.3 & 149 \\
\midrule
4 & \footnotesize GFlops & 28.96 & 54.91 & 55.98 & 61.92 & 65.35 & 66.44 & 70.85 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 6.31 & 6.31 & 6.31 & 12.6 & 25.2 & 50.5 & 101 \\
\midrule
2 & \footnotesize GFlops & 26.55 & 39.49 & 40.18 & 44.54 & 47.60 & 50.84 & 50.80 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 4.69 & 4.69 & 4.69 & 9.38 & 18.8 & 37.5 & 75.0 \\
\bottomrule
\end{tabular}
\caption{Performance and arithmetic intensity of stencils with non-tiled, spatially tiled, and time-tiled computations and time tile sizes 1, 2, 4, 8, 16. Tile sizes used to calculate arithmetic intensity available in project archive.}
\label{tab:laplace-roofline}
\end{table}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{axis}[
width=0.7\textwidth,
legend style={at={(1.05,0.95)},anchor=north west},
xlabel={Arithmetic intensity},
ylabel={GFlops achieved},
xmode=log,
log basis x={2},
ymode=log,
log basis y={2},
log ticks with fixed point,
]
\addplot table [x=oi,y=gflops,col sep=comma] {data/laplace-roof-so16.csv};
\addplot table [x=oi,y=gflops,col sep=comma] {data/laplace-roof-so8.csv};
\addplot table [x=oi,y=gflops,col sep=comma] {data/laplace-roof-so4.csv};
\addplot table [x=oi,y=gflops,col sep=comma] {data/laplace-roof-so2.csv};
\legend{Time-tiling so16,Time-tiling so8,Time-tiling so4,Time-tiling so2}
% roofline
\addplot [domain=2:15.15,name path=A] {17.3*x};
\addplot [domain=15.15:150] {262.01};
\end{axis}
\end{tikzpicture}
\caption{Graph of performance against arithmetic intensity for the Laplace operator, grid size \(16 \times 600^3\). As predicted by the roofline model, GFlops achieved increases more for stencils of lower arithmetic intensity; observe that for space order 16, GFlops achieved is nearly constant. The solid line is the theoretical maximum predicted by the roofline model.}
\label{fig:laplace-roofline}
\end{figure}

Table~\ref{tab:laplace-roofline} gives the arithmetic intensity and Devito-reported performance for each data point.
Note that arithmetic intensity increases significantly from a space-order of 2 to 16.
At the same time, reported GFlops of spatially tiled code increase dramatically from 15\% of that achieved by the \emph{LINPACK} benchmark, to over 35\%.
Therefore, we expect that we are nearing the computational bound of our test machine, and in accordance with the roofline model, would expect little improvement from memory bandwidth improvements such as time-tiling.

Figure~\ref{fig:laplace-roofline} is the corresponding plot to Table~\ref{tab:laplace-roofline}.
Note that we have only plotted the time-tiled results, as time-tiling with a time tile size of 1 is equivalent to spatial tiling and the results are nearly indistinguishable.


\section{Performance of the acoustic wave equation operator}
\label{sec:perf-awe}

\subsection{Application of the operator}
The acoustic wave equation (AWE) determines the propagation of acoustic waves, describing velocity as a function of space and time.
In our evaluation, we again used three spatial dimensions and a time dimension, with deterministically generated input.

In this section, the family of stencils generated by Devito are the acoustic wave equation operators governing wave propagation only,\footnote{Not including sources and receivers, required for some applications.} with space orders 4, 6, 8, 12, and 16.
Importantly for our evaluation, stencils generated by acoustic wave equation operator have lower arithmetic intensity than those from the Laplace operator, allowing us to distinguish spatially and time-tiled results more easily.

\subsection{Results}

Again, the grid size of \(512^3\) and a time buffer of 17 time iterations was chosen primarily as it was the largest grid that fulfilled our memory constraint.
Hence numerical verification was only performed for the last 17 iterations; nevertheless these iterations would represent the largest possible divergence of values, providing a reliable check of validity.
A buffer of at least 17 time iterations was necessary for the auto-tuner.

\begin{table}[p]
\centering
\begin{tabular}{rr|ccccc}
\toprule
& Grid size & \multicolumn{5}{c}{\( 512^3 \)} \\
& Space-order & 4 & 6 & 8 & 12 & 16 \\
\midrule
N & \footnotesize runtime (s) & 7.205 & 8.560 & 9.898 & 12.981 & 16.433 \\
% & \footnotesize GFlops      & 17.44 & 17.45 & 17.46 & 16.86 & 16.07 \\
S & \footnotesize runtime (s) & 4.558 & 4.595 & 4.655 & 4.892 & 5.608 \\
T & \footnotesize runtime (s) & 2.492 & 2.688 & 2.941 & 3.660 & 4.468 \\
& \footnotesize decrease (\%) & 45.3\% & 41.5\% & 36.8\% & 25.2\% & 20.3\% \\
\midrule
(t,8) & \footnotesize runtime (s) & * & * & 3.601 & 3.939 & 4.468 \\
(t,6) & \footnotesize runtime (s) & * & * & 3.348 & 3.660 & - \\
(t,4) & \footnotesize runtime (s) & 2.857 & 2.911 & 2.941 & - & - \\
(t,3) & \footnotesize runtime (s) & 2.688 & 2.688 & - & - & - \\
(t,2) & \footnotesize runtime (s) & 2.492 & - & - & - & - \\
\bottomrule
\end{tabular}
\caption{Runtimes (minimum of 10 trials) from using the acoustic wave equation operator. N, S, T represent minimum runtimes without tiling, with spatial tiling, and with time-tiling respectively. (t,\(k\)) indicates results for time-tiling with a skewing factor of \(k\); T indicates the minimum of these. `-' and `*' denote invalid skewing factor and not tested respectively. Decrease is from spatial tiling to time-tiling.}
\label{tab:awe-results}
\end{table}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{axis}[
width=0.7\textwidth,
legend style={at={(0.05,0.95)},anchor=north west},
xlabel={Space order},
ylabel={Runtime(s)},
ytick distance=2,
]
\addplot table [x=sp,y=run,col sep=comma] {data/awe-nt512.csv};
\addplot table [x=sp,y=run,col sep=comma] {data/awe-sp512.csv};
\addplot table [x=sp,y=run,col sep=comma] {data/awe-tm512.csv};
\legend{Non-tiled,Space-tiling,Time-tiling}
\end{axis}
\end{tikzpicture}
\caption{Non-tiled, spatially tiled and time-tiled runtimes with stencils from the acoustic wave equation operator.}
\label{fig:awe-runtime}
\end{figure}

In Table~\ref{tab:awe-results}, we again observe the greatest decrease in runtime (45\%) at the lowest space orders, tapering off as the space order increases, although a minimal gain of 20\% is still had for the largest space order tested.
There is a large step in runtime decrease (36.8\% to 25.2\%) between space orders 8 and 12, whereas the steps between each of the other space orders are less than 5\%.
Note that we have excluded some combinations from testing based on observations from the Laplace operator and the other combinations with this operator, which we discuss in Section~\ref{sec:eval-skewing-effect}.

Figure~\ref{fig:awe-runtime} gives the corresponding graph; we are able to make the same observations as for the Laplace stencils.
However, with the acoustic wave equation, we observe that time-tiling always gives a significant decrease in runtime over spatial tiling, this is likely due to the lower arithmetic intensity of these stencils.

In all cases, the minimum runtime was produced with the smallest valid skewing factor, even if it was not a power of two.
Additionally, all of the minimum runtimes occurred with the auto-tuner choosing a time tile size of 16.

\begin{table}[p]
\centering
\begin{tabular}{cr|c|c|ccccc}
\toprule
			& & N & S & \multicolumn{5}{c}{T; time tile size} \\
Space-order & &   &   & 1 & 2 & 4 & 8 & 16 \\
\midrule
16 & \footnotesize GFlops & 16.07 & 47.10 & 47.52 & 54.38 & 58.06 & 57.75 & 59.11 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 4.42 & 4.42 & 4.42 & 8.84 & 17.7 & 35.4 & 70.7 \\
\midrule
12 & \footnotesize GFlops & 16.86 & 44.75 & 44.38 & 52.43 & 57.99 & 57.98 & 59.82 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 3.36 & 3.36 & 3.36 & 6.72 & 13.4 & 26.9 & 53.8 \\
\midrule
8 & \footnotesize GFlops & 17.46 & 37.12 & 36.96 & 47.21 & 54.46 & 55.74 & 58.76 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 2.89 & 2.89 & 2.89 & 5.78 & 11.56 & 23.1 & 46.2 \\
\midrule
6 & \footnotesize GFlops & 17.45 & 32.51 & 32.39 & 42.65 & 50.40 & 53.11 & 55.57 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 2.50 & 2.50 & 2.50 & 5.00 & 10.0 & 20.0 & 40.0 \\
\midrule
4 & \footnotesize GFlops & 17.44 & 27.57 & 27.49 & 37.52 & 45.12 & 48.17 & 50.44 \\
\multicolumn{2}{r|}{\footnotesize arith. intensity} & 2.10 & 2.10 & 2.10 & 4.20 & 8.40 & 16.8 & 33.6 \\
\bottomrule
\end{tabular}
\caption{Performance and arithmetic intensity of stencils with non-tiled, spatially tiled, and time-tiled computations and time tile sizes 1, 2, 4, 8, 16. Data from minimum runtime trials for each parameter.}
\label{tab:awe-roofline}
\end{table}

\begin{figure}[p]
\centering
\begin{tikzpicture}
\begin{axis}[
width=0.7\textwidth,
legend style={at={(0.95,0.95)},anchor=north east},
xlabel={Arithmetic intensity},
ylabel={GFlops achieved},
ytick distance=10,
xmode=log,
log basis x={2},
log ticks with fixed point,
]
\addplot table [x=oi,y=gflops,col sep=comma] {data/awe-roof-so16.csv};
\addplot table [x=oi,y=gflops,col sep=comma] {data/awe-roof-so12.csv};
\addplot table [x=oi,y=gflops,col sep=comma] {data/awe-roof-so8.csv};
\addplot table [x=oi,y=gflops,col sep=comma] {data/awe-roof-so6.csv};
\addplot table [x=oi,y=gflops,col sep=comma] {data/awe-roof-so4.csv};

\addplot [domain=2:5.5] {17.3*x};
\legend{Time-tiling so16,Time-tiling so12, Time-tiling so8,Time-tiling so6, Time-tiling so4}
\end{axis}
\end{tikzpicture}
\caption{Graph of performance against arithmetic intensity for the acoustic wave equation operator, grid size \(512^3\). Spatial tiling omitted as results are nearly identical to time tile size 1. The solid line is the theoretical maximum predicted by the roofline model; performance limit omitted to avoid scaling.}
\label{fig:awe-roofline}
\end{figure}

Table~\ref{tab:awe-roofline} gives the arithmetic intensity and Devito-reported performance for stencils of varying space order time tile size.
To gather these results, time tile size was fixed and the auto-tuner was used to search for the best choice of spatial tile sizes.
This is to produce an analysis of the arithmetic intensity under time-tiling and performance gains.

Figure~\ref{fig:awe-roofline} is the corresponding roofline plot from the table.

Finally, we observe that the maximum achieved performance for any of these stencils is less than 60 GFlops, compared to over 90 GFlops using the Laplace operator.
A possible reason for this is the lower inherent arithmetic intensity of the acoustic wave equation stencils.


\section{Effect of the time tile size}
\label{sec:tt-size-effect}

Note that time-tiling with a time tile size of 1 is an analogue of spatial tiling, as each time iteration occurs with a new iteration of the time tile loop, and the incremental time loop is of no use.

With the acoustic wave equation operator (Figure~\ref{fig:awe-roofline}), we notice that stencils with low space order benefit from increases in tile size up to 16 and possibly beyond, while those with higher space orders have little performance gains after a time tile size of 4 or 8.

\wip{critique in section}
In order to explain this, we consider the arithmetic intensity estimator which we introduced in Section~\ref{sec:arithmetic-intensity}.


\section{Effect of the skewing factor}
\label{sec:eval-skewing-effect}

\paragraph{Arithmetic intensity}
We do not propose changing the measure of arithmetic intensity of a stencil computation when skewing, as the same data is required for each computation, and the ordering of computations has not changed.\footnote{For a more concrete understanding of this, one may appeal to the polyhedral model which is beyond the scope of this work.}
Nevertheless, due to data non-alignment with odd skewing factors, skewing \emph{may} have the impact of reducing the effective arithmetic intensity, especially if there is a memory bandwidth bottleneck.
We believe that this is overwhelmingly offset by the increase due to time-tiling.\footnote{The reader observes that time-tiling is intended to increase (minimally double) the arithmetic intensity, and a data alignment issue will not reduce the arithmetic intensity by more than half. Additionally, the nature of the stencil means that data neighbouring a dependency would often have to be loaded in any case, to calculate neighbouring points.}

Empirically, observe that in all but one case, time-tiling with a smaller skewing factor produces a lower runtime than a larger skewing factor, and that there is a progressive increase in runtime as the skewing factor increases.
This held for our test machine even if the skewing factor was not a power of two, such as 3 or 6, which were compared against skewing factors of 4 and 8 respectively.

However, it is important to note that this may be architecture-dependent, and should be tested on other architectures rather than assumed.
Further, we have only tested against 10 members across two families of stencils, which may not be fully representative of stencils in general.


\section{Limitations and further evaluation}
\label{sec:further-eval}
% "Why I could be wrong/this isn't representative of real world problems"

We were careful to guarantee the validity of our specific results, as documented in our testing methodology; this section illustrates how stronger conclusions may be drawn if the limitations were surmounted.


\subsection{Realism of test problems}

\subsubsection{Source and receiver loops}
Previously seen in Section~\ref{sec:impl-imperfect}, our implementation of time-tiling is unable to handle imperfectly-nested loops, source and receiver loops in particular.
As these are an important case for Devito to optimise, it is necessary to implement support for source and receiver loops and validate the results from our performance testing without these loops.

\subsubsection{Operators}
We have analysed stencils from two families of operators; one family, the acoustic wave equation, is extremely important in Devito's original target domain,
making it especially relevant.
However, there are other closely-related families of stencils from wave equations that are also highly relevant to Devito's use cases, and it would be beneficial to perform a comparative evaluation between them.

\subsubsection{Problem sizes}
We were limited to 64GB of memory on our test machine.
As we had to choose large enough spatial dimensions that each time iteration would dwarf the processor's cache, we were restricted to spatial dimensions of \(500 \times 500 \times 500 \) and larger.
This in turn restricted the number of time iterations we could store, even using time-buffering.
Indeed, the auto-tuner required at least 17 iterations to test time tile sizes up to 16, we were effectively prevented from testing time tile sizes of 32 (requiring 33 iterations of storage), as additional space was required for numerical verification.

Therefore, we were unable to perform analysis with both larger problem domains, or larger time tile sizes, which would have enabled a more complete evaluation.


\subsection{Test architecture}
Our testing was completed on a single-socket machine with one 8-core Sandy Bridge Xeon processor, and all tests were run with 16 threads, which it supports.
This provides a limited perspective on how time-tiling may perform on other systems and architectures, particularly those with more cores, cache, or distributed memory.


\subsection{Memory analyses}
For a more in depth study, memory analyses measuring cache misses and memory traffic should be performed, to investigate how time-tiling has improved these.
Additionally, such analyses would reveal more information on the true arithmetic intensity of the computation.
This would allow us to determine how the bottlenecks have changed after time-tiling, how far the performance is from theoretical limits, and reveal further areas of optimisation.


\subsection{Comparison to spatial tiling}
In our analysis, we have compared time-tiling to spatial tiling code, both of which used our new tiling algorithm which utilised min/max bounding.
It is possible that this is slower for spatial tiling than the previous remainder loop tiling algorithm in Devito.

We have decided to accept this possibility, as any difference is unlikely to be significant; remainder loops incur a synchronisation penalty, whereas min/max bounding requires a few additional arithmetic operations.
Neither of these should take up a significant amount of time compared to the time for the stencil computation.

As a note, it may be possible to reduce the bounding overhead slightly by avoiding the floating-point \texttt{fmin} and \texttt{fmax} functions in bounding, as only integer comparisons are needed.
This is documented in Section~\ref{sec:impl-minor}.


\subsection{Bounding the arithmetic intensity estimator}


\section{Summary}
\label{sec:eval-conclusion}

\wip{check this late}

In this chapter we presented a robust testing methodology and model to understand the performance increase from time-tiling, and when the decrease in runtime is maximal.
Through our investigation, we discovered a runtime decrease of up to 45\% in an extreme case and at least 20\% in other cases using multiple real-world stencils from the family of acoustic wave equation operators.

We additionally presented a simple estimator for arithmetic intensity under time-tiling, establishing its bounds and limitations, and use it to successfully model the performance benefit of our time-tiling transformation.

\paragraph{A final remark}
Previous analysis of the stencil of space order 8 with the acoustic wave equation operator yielded a decrease in runtime of 27.5\%, when passing non-tiled code from Devito to the polyhedral compiler CLooG~\cite{dylan}.
We surpassed this, demonstrating a 36.8\% decrease in runtime for the same stencil with our native time-tiling algorithm in Devito, albeit with the power of Devito auto-tuner and a larger time tile size.
